name: Test Scraper

on:
  pull_request:
    branches:
      - main
    paths:
      - '**.py'
      - 'requirements.txt'
      - '.github/workflows/test.yml'

  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-22.04  # Use Ubuntu 22.04 for better Playwright compatibility

    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pylint flake8

      - name: Install Playwright browsers
        run: |
          playwright install chromium
          playwright install-deps chromium
        env:
          PLAYWRIGHT_BROWSERS_PATH: ${{ runner.temp }}/playwright

      - name: Lint with flake8
        continue-on-error: true
        run: |
          # Stop the build if there are Python syntax errors or undefined names
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          # Exit-zero treats all errors as warnings
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=120 --statistics

      - name: Check code with pylint
        continue-on-error: true
        run: |
          pylint scraper.py pipeline.py --max-line-length=120 || true

      - name: Test imports
        run: |
          python -c "from scraper import PasardanaScraper; print('✓ scraper.py imports OK')"
          python -c "from pipeline import PasardanaPipeline; print('✓ pipeline.py imports OK')"

      - name: Dry run test
        run: |
          echo "Testing scraper initialization..."
          python -c "
          from scraper import PasardanaScraper
          import asyncio

          async def test():
              scraper = PasardanaScraper(headless=True)
              print(f'✓ Scraper initialized')
              print(f'  - Base URL: {scraper.base_url}')
              print(f'  - Output dir: {scraper.data_output_dir}')
              print(f'  - Max retries: {scraper.max_retries}')

          asyncio.run(test())
          "

      - name: Test summary
        if: always()
        run: |
          echo "## Test Results - Python ${{ matrix.python-version }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Python Version**: ${{ matrix.python-version }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All import and initialization tests completed." >> $GITHUB_STEP_SUMMARY
